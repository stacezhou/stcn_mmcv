{"env_info": "sys.platform: linux\nPython: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]\nCUDA available: True\nGPU 0,1,2: NVIDIA GeForce RTX 3090\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 11.3, V11.3.109\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.8.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 8.0.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.9.0\nOpenCV: 4.5.5\nMMCV: 1.5.0\nMMCV Compiler: GCC 7.5\nMMCV CUDA Compiler: 11.3\nMMDetection: 2.23.0+5b74091", "config": "model = dict(\n    type='STCN',\n    init_cfg=dict(type='Kaiming', layer='Conv2d'),\n    seg_background=False,\n    max_per_frame=2,\n    key_encoder=dict(\n        type='KeyEncoder',\n        backbone=dict(\n            type='ResNet',\n            depth=50,\n            out_indices=(0, 1, 2),\n            frozen_stages=3,\n            init_cfg=dict(\n                type='Pretrained', checkpoint='torchvision://resnet50')),\n        key_proj=dict(\n            type='KeyProjection', indim=1024, keydim=64, ortho_init=True),\n        key_comp=dict(type='KeyProjection', indim=1024, keydim=512)),\n    value_encoder=dict(\n        type='ValueEncoder',\n        backbone=dict(\n            type='ResNet', depth=18, in_channels=4, out_indices=(2, )),\n        feature_fusion=dict(type='FeatureFusionBlock', indim=1280,\n                            outdim=512)),\n    mask_decoder=dict(type='MaskDecoder', indim=512),\n    memory=dict(\n        type='AffinityMemoryBank',\n        top_k=-1,\n        mem_every=5,\n        include_last=False,\n        thin_reading_scale=8),\n    loss_fn=dict(\n        type='BootstrappedCE', start_warm=10000, end_warm=40000, top_p=0.15))\ncustom_imports = dict(\n    imports=['stcn.loss.bce', 'stcn.model'], allow_failed_imports=False)\ncheckpoint_config = dict(interval=1)\nlog_config = dict(\n    interval=25,\n    hooks=[dict(type='TextLoggerHook'),\n           dict(type='TensorboardLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\nopencv_num_threads = 0\nmp_start_method = 'fork'\nfind_unused_parameters = True\ndata = dict(\n    workers_per_gpu=0,\n    samples_per_gpu=4,\n    nums_frame=3,\n    train=dict(\n        type='VOSDataset',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadMaskFromFile'),\n            dict(type='EnAlbu'),\n            dict(\n                type='Albu',\n                transforms=[\n                    dict(\n                        type='RandomResizedCrop',\n                        height=480,\n                        width=896,\n                        scale=(0.8, 1.0),\n                        ratio=(0.7, 1.3),\n                        p=1),\n                    dict(type='ShiftScaleRotate', p=0.9),\n                    dict(\n                        type='RandomBrightnessContrast',\n                        brightness_limit=[0.1, 0.3],\n                        contrast_limit=[0.1, 0.3],\n                        p=0.2),\n                    dict(type='ChannelShuffle', p=0.1),\n                    dict(\n                        type='OneOf',\n                        transforms=[\n                            dict(\n                                type='RGBShift',\n                                p=1.0,\n                                r_shift_limit=(-20, 20),\n                                g_shift_limit=(-20, 20),\n                                b_shift_limit=(-20, 20))\n                        ],\n                        p=0.1)\n                ],\n                keymap=dict(gt_mask='masks', img='image')),\n            dict(type='OutAlbu'),\n            dict(type='MergeImgMask'),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(type='Pad', size_divisor=32),\n            dict(type='SplitImgMask'),\n            dict(type='ImageToTensor', keys=['gt_mask']),\n            dict(\n                type='ToDataContainer',\n                fields=({\n                    'key': 'gt_mask',\n                    'stack': True\n                }, )),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='DefaultFormatBundle'),\n            dict(type='SafeCollect', keys=['img', 'gt_mask'])\n        ],\n        frame_limit=30,\n        shuffle_videos=True,\n        random_skip=False,\n        max_skip=5,\n        min_skip=1,\n        max_objs_per_gpu=4,\n        max_per_frame=2,\n        image_root='/data/YouTube/train_480p/JPEGImages',\n        mask_root='/data/YouTube/train_480p/Annotations'),\n    val=dict(\n        type='VOSDataset',\n        test_mode=True,\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadMaskFromFile'),\n            dict(type='MergeImgMask'),\n            dict(type='Pad', size_divisor=16),\n            dict(type='SplitImgMask'),\n            dict(type='ImageToTensor', keys=['gt_mask']),\n            dict(\n                type='ToDataContainer',\n                fields=({\n                    'key': 'gt_mask',\n                    'stack': True\n                }, )),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='SafeCollect',\n                keys=['img', 'gt_mask'],\n                meta_keys=('flag', 'filename', 'ori_filename', 'labels',\n                           'ori_shape', 'img_shape', 'pad_shape',\n                           'scale_factor', 'flip', 'flip_direction',\n                           'img_norm_cfg'))\n        ],\n        wo_mask_pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='Pad', size_divisor=16),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='SafeCollect',\n                keys=['img'],\n                meta_keys=('flag', 'filename', 'ori_filename', 'labels',\n                           'ori_shape', 'img_shape', 'pad_shape',\n                           'scale_factor', 'flip', 'flip_direction',\n                           'img_norm_cfg'))\n        ],\n        image_root='/data/YouTube/debug/JPEGImages',\n        mask_root='/data/YouTube/debug/valid_Annotations',\n        palette='/data/YouTube/valid/Annotations/0a49f5265b/00000.png'),\n    test=dict(\n        type='VOSDataset',\n        test_mode=True,\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadMaskFromFile'),\n            dict(type='MergeImgMask'),\n            dict(type='Pad', size_divisor=16),\n            dict(type='SplitImgMask'),\n            dict(type='ImageToTensor', keys=['gt_mask']),\n            dict(\n                type='ToDataContainer',\n                fields=({\n                    'key': 'gt_mask',\n                    'stack': True\n                }, )),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='SafeCollect',\n                keys=['img', 'gt_mask'],\n                meta_keys=('flag', 'filename', 'ori_filename', 'labels',\n                           'ori_shape', 'img_shape', 'pad_shape',\n                           'scale_factor', 'flip', 'flip_direction',\n                           'img_norm_cfg'))\n        ],\n        wo_mask_pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='Pad', size_divisor=16),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='SafeCollect',\n                keys=['img'],\n                meta_keys=('flag', 'filename', 'ori_filename', 'labels',\n                           'ori_shape', 'img_shape', 'pad_shape',\n                           'scale_factor', 'flip', 'flip_direction',\n                           'img_norm_cfg'))\n        ],\n        image_root='/data/YouTube/valid/JPEGImages',\n        mask_root='/data/YouTube/valid/Annotations',\n        palette='/data/YouTube/valid/Annotations/0a49f5265b/00000.png'))\noptimizer = dict(type='Adam', lr=0.0005)\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(\n    policy='step',\n    by_epoch=False,\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=0.3333333333333333,\n    step=[10000])\nrunner = dict(type='EpochBasedRunner', max_epochs=20)\nfp16 = dict(loss_scale=512.0)\nevaluation = dict(start=100, save_best='mIoU', interval=200, by_epoch=False)\nwork_dir = './work_dirs/stcn_origin'\nvalidate = True\nauto_resume = False\ngpu_ids = range(0, 3)\nseed = 0\n", "seed": 0, "exp_name": "stcn_origin.py", "hook_msgs": {}}
{"mode": "train", "epoch": 1, "iter": 25, "lr": 0.00017, "memory": 5401, "data_time": 0.53371, "bce_p": 1.0, "loss": 124.77622, "time": 1.19484}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.00018, "memory": 5401, "data_time": 0.49161, "bce_p": 1.0, "loss": 25.44655, "time": 1.08033}
{"mode": "train", "epoch": 1, "iter": 75, "lr": 0.00019, "memory": 5401, "data_time": 0.44687, "bce_p": 1.0, "loss": 20.30453, "time": 1.04263}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.0002, "memory": 5401, "data_time": 0.98969, "bce_p": 1.0, "loss": 21.34445, "time": 1.63586}
{"mode": "val", "epoch": 1, "iter": 360, "lr": 0.0002, "mIoU": 0.25259, "F": 0.16513}
{"mode": "train", "epoch": 1, "iter": 125, "lr": 0.00021, "memory": 5402, "data_time": 2.8402, "bce_p": 1.0, "loss": 39.74923, "time": 3.42317}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.00022, "memory": 5402, "data_time": 0.47052, "bce_p": 1.0, "loss": 8.43497, "time": 1.03764}
{"mode": "train", "epoch": 1, "iter": 175, "lr": 0.00022, "memory": 5402, "data_time": 0.4591, "bce_p": 1.0, "loss": 4.25169, "time": 1.06242}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.00023, "memory": 5402, "data_time": 0.43992, "bce_p": 1.0, "loss": 2.6944, "time": 1.02715}
{"mode": "train", "epoch": 1, "iter": 225, "lr": 0.00024, "memory": 5402, "data_time": 0.44805, "bce_p": 1.0, "loss": 3.7267, "time": 1.0405}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.00025, "memory": 5402, "data_time": 0.44534, "bce_p": 1.0, "loss": 3.5387, "time": 1.05094}
{"mode": "train", "epoch": 1, "iter": 275, "lr": 0.00026, "memory": 5402, "data_time": 0.4658, "bce_p": 1.0, "loss": 3.1157, "time": 1.04753}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.00027, "memory": 5402, "data_time": 0.44128, "bce_p": 1.0, "loss": 3.37782, "time": 1.02544}
{"mode": "val", "epoch": 1, "iter": 360, "lr": 0.00027, "mIoU": 0.35823, "F": 0.24328}
{"mode": "train", "epoch": 1, "iter": 325, "lr": 0.00027, "memory": 5402, "data_time": 2.83063, "bce_p": 1.0, "loss": 1.85153, "time": 3.43341}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.00028, "memory": 5402, "data_time": 1.58256, "bce_p": 1.0, "loss": 1.52397, "time": 2.75897}
{"mode": "train", "epoch": 1, "iter": 375, "lr": 0.00029, "memory": 5402, "data_time": 0.69448, "bce_p": 1.0, "loss": 2.69046, "time": 1.24003}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.0003, "memory": 5402, "data_time": 0.42199, "bce_p": 1.0, "loss": 2.13362, "time": 0.97699}
{"mode": "train", "epoch": 1, "iter": 425, "lr": 0.00031, "memory": 5402, "data_time": 0.9183, "bce_p": 1.0, "loss": 1.58293, "time": 1.64993}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.00032, "memory": 5402, "data_time": 0.40773, "bce_p": 1.0, "loss": 2.58352, "time": 0.95718}
{"mode": "train", "epoch": 1, "iter": 475, "lr": 0.00032, "memory": 5402, "data_time": 0.40746, "bce_p": 1.0, "loss": 1.62441, "time": 0.98784}
{"mode": "train", "epoch": 1, "iter": 500, "lr": 0.00033, "memory": 5402, "data_time": 0.41259, "bce_p": 1.0, "loss": 1.98458, "time": 0.99573}
{"mode": "val", "epoch": 1, "iter": 360, "lr": 0.00033, "mIoU": 0.35489, "F": 0.27403}
{"mode": "train", "epoch": 1, "iter": 525, "lr": 0.00034, "memory": 5402, "data_time": 2.84783, "bce_p": 1.0, "loss": 2.56733, "time": 3.42811}
{"mode": "train", "epoch": 1, "iter": 550, "lr": 0.00035, "memory": 5402, "data_time": 0.4364, "bce_p": 1.0, "loss": 2.43626, "time": 1.01274}
{"mode": "train", "epoch": 1, "iter": 575, "lr": 0.00036, "memory": 5402, "data_time": 0.43661, "bce_p": 1.0, "loss": 1.83936, "time": 1.0258}
{"mode": "train", "epoch": 1, "iter": 600, "lr": 0.00037, "memory": 5402, "data_time": 0.77651, "bce_p": 1.0, "loss": 1.47988, "time": 1.3842}
{"mode": "train", "epoch": 1, "iter": 625, "lr": 0.00037, "memory": 5402, "data_time": 0.57943, "bce_p": 1.0, "loss": 1.49601, "time": 1.29757}
{"mode": "train", "epoch": 1, "iter": 650, "lr": 0.00038, "memory": 5402, "data_time": 0.452, "bce_p": 1.0, "loss": 1.62963, "time": 1.03434}
{"mode": "train", "epoch": 1, "iter": 675, "lr": 0.00039, "memory": 5402, "data_time": 0.43512, "bce_p": 1.0, "loss": 2.22017, "time": 1.02952}
{"mode": "train", "epoch": 1, "iter": 700, "lr": 0.0004, "memory": 5402, "data_time": 0.44629, "bce_p": 1.0, "loss": 1.44072, "time": 1.04236}
{"mode": "val", "epoch": 1, "iter": 360, "lr": 0.0004, "mIoU": 0.39558, "F": 0.31777}
{"mode": "train", "epoch": 1, "iter": 725, "lr": 0.00041, "memory": 5402, "data_time": 2.83187, "bce_p": 1.0, "loss": 2.13653, "time": 3.41799}
{"mode": "train", "epoch": 1, "iter": 750, "lr": 0.00042, "memory": 5402, "data_time": 0.44997, "bce_p": 1.0, "loss": 1.20408, "time": 1.00634}
{"mode": "train", "epoch": 1, "iter": 775, "lr": 0.00042, "memory": 5402, "data_time": 0.43949, "bce_p": 1.0, "loss": 1.78854, "time": 1.06367}
{"mode": "train", "epoch": 1, "iter": 800, "lr": 0.00043, "memory": 5402, "data_time": 0.43228, "bce_p": 1.0, "loss": 1.46072, "time": 1.0017}
{"mode": "train", "epoch": 1, "iter": 825, "lr": 0.00044, "memory": 5402, "data_time": 0.45036, "bce_p": 1.0, "loss": 1.21613, "time": 1.02072}
{"mode": "train", "epoch": 1, "iter": 850, "lr": 0.00045, "memory": 5402, "data_time": 0.44771, "bce_p": 1.0, "loss": 1.67672, "time": 1.02008}
{"mode": "train", "epoch": 1, "iter": 875, "lr": 0.00046, "memory": 5402, "data_time": 0.4405, "bce_p": 1.0, "loss": 1.97082, "time": 1.02559}
{"mode": "train", "epoch": 1, "iter": 900, "lr": 0.00047, "memory": 5402, "data_time": 0.9156, "bce_p": 1.0, "loss": 2.52548, "time": 1.65721}
{"mode": "val", "epoch": 1, "iter": 360, "lr": 0.00047, "mIoU": 0.39767, "F": 0.21768}
{"mode": "train", "epoch": 1, "iter": 925, "lr": 0.00047, "memory": 5402, "data_time": 2.83434, "bce_p": 1.0, "loss": 2.0977, "time": 3.43333}
{"mode": "train", "epoch": 1, "iter": 950, "lr": 0.00048, "memory": 5402, "data_time": 0.4285, "bce_p": 1.0, "loss": 1.15118, "time": 0.99262}
{"mode": "train", "epoch": 1, "iter": 975, "lr": 0.00049, "memory": 5402, "data_time": 0.92642, "bce_p": 1.0, "loss": 1.58128, "time": 1.54769}
{"mode": "train", "epoch": 1, "iter": 1000, "lr": 0.0005, "memory": 5402, "data_time": 1.55928, "bce_p": 1.0, "loss": 1.43784, "time": 2.89612}
{"mode": "train", "epoch": 1, "iter": 1025, "lr": 0.0005, "memory": 5402, "data_time": 0.87231, "bce_p": 1.0, "loss": 0.92237, "time": 1.54284}
{"mode": "train", "epoch": 1, "iter": 1050, "lr": 0.0005, "memory": 5402, "data_time": 0.54921, "bce_p": 1.0, "loss": 1.90882, "time": 1.1481}
{"mode": "train", "epoch": 1, "iter": 1075, "lr": 0.0005, "memory": 5402, "data_time": 0.53917, "bce_p": 1.0, "loss": 1.31235, "time": 1.12928}
{"mode": "train", "epoch": 1, "iter": 1100, "lr": 0.0005, "memory": 5402, "data_time": 0.50398, "bce_p": 1.0, "loss": 1.11361, "time": 1.10593}
{"mode": "val", "epoch": 1, "iter": 360, "lr": 0.0005, "mIoU": 0.51336, "F": 0.41037}
{"mode": "train", "epoch": 1, "iter": 1125, "lr": 0.0005, "memory": 5402, "data_time": 3.38824, "bce_p": 1.0, "loss": 1.01325, "time": 4.14947}
{"mode": "train", "epoch": 1, "iter": 1150, "lr": 0.0005, "memory": 5402, "data_time": 0.54513, "bce_p": 1.0, "loss": 1.034, "time": 1.21387}
{"mode": "train", "epoch": 1, "iter": 1175, "lr": 0.0005, "memory": 5402, "data_time": 0.52444, "bce_p": 1.0, "loss": 1.19613, "time": 1.08922}
{"mode": "train", "epoch": 1, "iter": 1200, "lr": 0.0005, "memory": 5402, "data_time": 0.68975, "bce_p": 1.0, "loss": 0.96081, "time": 1.26788}
{"mode": "train", "epoch": 1, "iter": 1225, "lr": 0.0005, "memory": 5402, "data_time": 0.87634, "bce_p": 1.0, "loss": 0.98084, "time": 1.52952}
{"mode": "train", "epoch": 2, "iter": 25, "lr": 0.0005, "memory": 5402, "data_time": 0.46146, "bce_p": 1.0, "loss": 5.79242, "time": 1.04317}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.0005, "memory": 5402, "data_time": 0.35723, "bce_p": 1.0, "loss": 1.89709, "time": 0.94416}
{"mode": "val", "epoch": 2, "iter": 360, "lr": 0.0005, "mIoU": 0.47422, "F": 0.3678}
{"mode": "train", "epoch": 2, "iter": 75, "lr": 0.0005, "memory": 5402, "data_time": 14.00057, "bce_p": 1.0, "loss": 0.61216, "time": 14.62193}
{"mode": "train", "epoch": 2, "iter": 100, "lr": 0.0005, "memory": 5402, "data_time": 0.52231, "bce_p": 1.0, "loss": 3.59514, "time": 1.11081}
{"mode": "train", "epoch": 2, "iter": 125, "lr": 0.0005, "memory": 5402, "data_time": 0.46856, "bce_p": 1.0, "loss": 535.43068, "time": 1.08488}
